{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Database Connection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "876046989adf1083"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "from recycle_conn_mysql import MYSQL_RECYCLE\n",
    "\n",
    "sql_connection = f\"mysql+pymysql://{MYSQL_RECYCLE.USER_NAME.value}:{MYSQL_RECYCLE.PASSWORD.value}@{MYSQL_RECYCLE.HOST.value}/{MYSQL_RECYCLE.NAME.value}\"\n",
    "\n",
    "recycle_db = create_engine(sql_connection, echo=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:32:49.947294400Z",
     "start_time": "2024-02-26T12:32:49.906123200Z"
    }
   },
   "id": "6eb33f08214ba261",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Creations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e5d178df391a52"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:32:53.003264500Z",
     "start_time": "2024-02-26T12:32:52.996326200Z"
    }
   },
   "outputs": [],
   "source": [
    "waste_detection_v8m = {\"model\": \"wasteDetection/wasteDetectionv8m.pt\",\n",
    "                       \"classNames\": [\"biodegradable\",\n",
    "                                      \"clothes\",\n",
    "                                      \"electronic\",\n",
    "                                      \"glass\",\n",
    "                                      \"paper\",\n",
    "                                      \"plastic\"]}\n",
    "\n",
    "recycle_class_names = [\"Can\", \"Glass\", \"Plastic\", \"glass\"]\n",
    "\n",
    "# Al parecer funcionan mejor los n en la web cam...\n",
    "recycle_detection_v8n = {\"model\": \"recycle/recycle_v8n.pt\",\n",
    "                         \"classNames\": recycle_class_names}\n",
    "recycle_detection_v8m = {\"model\": \"recycle/recycle_v8m.pt\",\n",
    "                         \"classNames\": recycle_class_names}\n",
    "\n",
    "# Subir manual porque pesa mÃ¡s de 100Mb\n",
    "recycle_detection_v8x = {\"model\": \"recycle/recycle_v8x.pt\",\n",
    "                         \"classNames\": recycle_class_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Instantiation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b24dfed1b72c227"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_detection = recycle_detection_v8n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:32:55.546656300Z",
     "start_time": "2024-02-26T12:32:55.533049300Z"
    }
   },
   "id": "d71bfdcabe3bb38e",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Running Object Detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c31e498f2851d66d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 (no detections), 229.0ms\n",
      "Speed: 14.7ms preprocess, 229.0ms inference, 5.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 128.0ms\n",
      "Speed: 4.3ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 126.2ms\n",
      "Speed: 3.5ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 178.0ms\n",
      "Speed: 4.0ms preprocess, 178.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 140.2ms\n",
      "Speed: 6.0ms preprocess, 140.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 119.6ms\n",
      "Speed: 2.1ms preprocess, 119.6ms inference, 0.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 126.6ms\n",
      "Speed: 2.1ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 134.8ms\n",
      "Speed: 2.1ms preprocess, 134.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 118.3ms\n",
      "Speed: 2.2ms preprocess, 118.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 118.2ms\n",
      "Speed: 4.4ms preprocess, 118.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 120.5ms\n",
      "Speed: 2.5ms preprocess, 120.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 115.1ms\n",
      "Speed: 2.2ms preprocess, 115.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 120.4ms\n",
      "Speed: 2.2ms preprocess, 120.4ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 162.7ms\n",
      "Speed: 1.1ms preprocess, 162.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 127.6ms\n",
      "Speed: 2.4ms preprocess, 127.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 142.0ms\n",
      "Speed: 2.2ms preprocess, 142.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 129.0ms\n",
      "Speed: 3.0ms preprocess, 129.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 118.3ms\n",
      "Speed: 2.2ms preprocess, 118.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 142.6ms\n",
      "Speed: 3.4ms preprocess, 142.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 117.0ms\n",
      "Speed: 3.2ms preprocess, 117.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 114.6ms\n",
      "Speed: 1.1ms preprocess, 114.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 133.5ms\n",
      "Speed: 4.7ms preprocess, 133.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 134.2ms\n",
      "Speed: 5.2ms preprocess, 134.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 104.4ms\n",
      "Speed: 1.1ms preprocess, 104.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 112.5ms\n",
      "Speed: 2.2ms preprocess, 112.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 110.0ms\n",
      "Speed: 2.2ms preprocess, 110.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 109.0ms\n",
      "Speed: 3.3ms preprocess, 109.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 96.6ms\n",
      "Speed: 2.2ms preprocess, 96.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 103.2ms\n",
      "Speed: 1.1ms preprocess, 103.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 106.0ms\n",
      "Speed: 2.2ms preprocess, 106.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 115.5ms\n",
      "Speed: 3.2ms preprocess, 115.5ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 107.6ms\n",
      "Speed: 3.4ms preprocess, 107.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 107.8ms\n",
      "Speed: 3.6ms preprocess, 107.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 102.9ms\n",
      "Speed: 2.4ms preprocess, 102.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 108.3ms\n",
      "Speed: 3.0ms preprocess, 108.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 96.0ms\n",
      "Speed: 2.2ms preprocess, 96.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 104.7ms\n",
      "Speed: 2.2ms preprocess, 104.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 139.9ms\n",
      "Speed: 3.1ms preprocess, 139.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 120.8ms\n",
      "Speed: 2.1ms preprocess, 120.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 128.7ms\n",
      "Speed: 2.4ms preprocess, 128.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 109.0ms\n",
      "Speed: 2.6ms preprocess, 109.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 104.8ms\n",
      "Speed: 2.5ms preprocess, 104.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 113.1ms\n",
      "Speed: 3.1ms preprocess, 113.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 107.2ms\n",
      "Speed: 2.6ms preprocess, 107.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 107.2ms\n",
      "Speed: 3.3ms preprocess, 107.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 105.6ms\n",
      "Speed: 2.3ms preprocess, 105.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "0: 480x640 (no detections), 104.6ms\n",
      "Speed: 2.2ms preprocess, 104.6ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math \n",
    "# start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# model\n",
    "model = YOLO(model_detection[\"model\"])\n",
    "\n",
    "# object classes\n",
    "classNames = model_detection[\"classNames\"]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "    # coordinates\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        for box in boxes:\n",
    "            # confidence\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            \n",
    "            if confidence > 0.5:\n",
    "                # bounding box\n",
    "                x1, y1, x2, y2 = box.xyxy[0]\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n",
    "                # put box in cam\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n",
    "        \n",
    "                # class name\n",
    "                cls = int(box.cls[0])\n",
    "                print(\"Class name -->\", classNames[cls])\n",
    "                print(\"Confidence --->\",confidence)\n",
    "    \n",
    "                # object details\n",
    "                org = [x1, y1]\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                fontScale = 1\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "    \n",
    "                cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "                \n",
    "                with Session(recycle_db) as conn:\n",
    "                    conn.execute( f\"insert into predictions(prediction, score, date) values('{classNames[cls]}',{confidence}, now())\" , dict())\n",
    "                    conn.commit()\n",
    "\n",
    "    cv2.imshow('Webcam', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T12:33:19.382394500Z",
     "start_time": "2024-02-26T12:33:00.065259300Z"
    }
   },
   "id": "12f698d2fdceced6",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
